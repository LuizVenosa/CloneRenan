{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get Captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "f9bb8323"
      },
      "outputs": [],
      "source": [
        "playlist_input = \"https://www.youtube.com/playlist?list=PLmbUlSQHQlvhEqMXztLb2ZnLDvg20J2nD\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a7e4f2b",
        "outputId": "45718ea8-bd63-41e4-8716-24c992b8dd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Playlist ID: PLmbUlSQHQlvhEqMXztLb2ZnLDvg20J2nD\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "playlist_id = None\n",
        "# Regex to extract playlist ID from various YouTube URL formats\n",
        "playlist_url_regex = r'(?:youtube\\.com\\/(?:[^\\/]+\\/.+?\\/|(?:v|e(?:mbed)?)\\/|.*[?&]list=)|youtu\\.be\\/)([^\"&?\\/ ]{11,})'\n",
        "\n",
        "match = re.search(playlist_url_regex, playlist_input)\n",
        "if match:\n",
        "    playlist_id = match.group(1)\n",
        "\n",
        "# If it's not a URL or the regex failed, assume the input is directly the playlist ID\n",
        "if not playlist_id:\n",
        "    playlist_id = playlist_input\n",
        "\n",
        "print(f\"Extracted Playlist ID: {playlist_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5911d05a",
        "outputId": "10ad6bc6-fa08-4fa5-949f-0dbd1323a9ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-api-python-client in c:\\programming\\envs\\clonerenan\\lib\\site-packages (2.187.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-python-client) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-python-client) (2.45.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-python-client) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (6.33.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.27.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.5)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\programming\\envs\\clonerenan\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Installed google-api-python-client.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade google-api-python-client\n",
        "print(\"Installed google-api-python-client.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "15b04db0",
        "outputId": "dd74b91b-42af-4747-c988-58316097f55d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YouTube API service initialized.\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient.discovery import build\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
        "# Placeholder for your API key. Replace with your actual key.\n",
        "YOUTUBE_API_KEY = api_key\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)\n",
        "print(\"YouTube API service initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb1c123b",
        "outputId": "53c24225-c2ea-4141-fffe-9267cfb2f933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max videos to process set to: 100\n"
          ]
        }
      ],
      "source": [
        "max_videos = 100\n",
        "print(f\"Max videos to process set to: {max_videos}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84890166",
        "outputId": "07ea1c17-8089-459f-9940-e29d25ce6ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100 video IDs.\n",
            "Video IDs: ['k5juTqk-OoA', 'VQo1Eut6jhA', 'hvHNbeTsneY', 'OgYJmEB7lQk', 'Zs7qVzVu8sA', '4raib3FSIdE', 'EHXRd4oNEqM', 'KA46LrBO7TM', '47KrW28W2YU', 'HEYfSKI-kWw', 'rK90XkzEvd0', 'dpwfv92XUIM', 'pbJIaUr-Sfg', 'c5C9wn6Kd-E', '1sS7XPc4PnQ', '14uO75YlYkA', 'k27pd5LLxEs', 'y3_4F0_PM_0', 'vaMPbvvFLXI', '5A2J7jSyTAo', 'mSD3QG-5Xzg', 'rnSRXbK7H4g', 'nBfKZpku4Vo', '5gcVK_XvxSQ', 'fngLDf_K0Lw', 'b5FAVx8h-MU', '3M0ziiToATw', 'Y0-NcZBwYxo', 'OlQ1ILcyXfk', 'fpQ1pmBX5Qk', 'Ed8NqOOzNkc', 'Wcrpxsc1sT0', 'CGC-y3ySlhA', 'DSeg7Hx_GLc', 'u5UbGUuvBnI', 'vtT-QtiuwxY', 'mla3BXFGXXk', 'JPpJhsUGn6w', 'JPKJiJJDBqU', 'fgF5u05wTYM', 'AlBJwRqfD8A', 'FsrIbZfjc38', 'dU4B3HrgBxM', 'TEJxyq-I2AM', 'MJbUW84XCho', '2jfISLM_ZDY', '7C2M9qDaMIU', '6lA_9iMf7Wk', '-YKYepbihEI', 'jkD0EzqUj4o', 'ciH6t0VMw-c', 'raFnAJ1g_tU', 'tTsR_1iMYXI', 's3RV5Yjze3Q', '7wS_pfMz90M', 'FTrMuF6A_bc', 'vSaYg7BF6Hg', 'bND2kvgqQ3E', 'XCidDCrvI1E', 'dInifOpWZqg', 'mi-RiCAEdRs', 'u4NwDAi5ab0', 'Ry_Fh9W7O6k', 'T-1eGfIE2FU', 'zaMR4vwcOkA', 'Bnw_e2661KA', 'NanWDE6VNhU', 'BZNpD3SBs4w', 'l6qtf2IIOWI', 'hmt7AcBGU0E', 'jn8pOdkomkw', '-loxrGHFXOY', 'FnQMfuQ1m-I', 'nN5k1DbW_Yw', 'R9tW1xGzVeU', '3HhYBo3djwg', 'I6xvW4FQ1a4', 'dngu62271WI', 'CxPp9_KgAOg', 'bB776wPOIpg', 'hMaaGfQ7xFg', 'NJkDTJrNOto', 'PU2DnJnVRXY', 'UNkzon9eqSM', 'V1KFnxzrgLE', 'OwK4ElWRgAs', 'O06_Bn21i34', 'U8rc_EmRYzs', 'lPnCSY0bR9I', '315u3iwIOgA', 'jXJUjLPllxU', 'zwOOdxm2DRQ', 'kWuMOIABg7w', 'qhcpStRgpVg', 'KS1JXojTKQo', 'xXjsU9h9ets', '3L2e1p5Tr1M', 'oahjvrfAaSg', 'umP0xoBxTVQ', 'igInYeNoQfs']\n"
          ]
        }
      ],
      "source": [
        "video_ids = []\n",
        "next_page_token = None\n",
        "\n",
        "while True:\n",
        "    request = youtube.playlistItems().list(\n",
        "        part=\"snippet\",\n",
        "        playlistId=playlist_id,\n",
        "        maxResults=50, # Max results per page\n",
        "        pageToken=next_page_token\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    for item in response['items']:\n",
        "        video_id = item['snippet']['resourceId']['videoId']\n",
        "        video_ids.append(video_id)\n",
        "        if len(video_ids) >= max_videos:\n",
        "            break\n",
        "\n",
        "    next_page_token = response.get('nextPageToken')\n",
        "    if not next_page_token or len(video_ids) >= max_videos:\n",
        "        break\n",
        "\n",
        "# Truncate video_ids to ensure it does not exceed max_videos\n",
        "video_ids = video_ids[:max_videos]\n",
        "\n",
        "print(f\"Found {len(video_ids)} video IDs.\")\n",
        "print(\"Video IDs:\", video_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afcd6517"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to create a directory named `captions` to store the downloaded caption files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be912989",
        "outputId": "b4eea6f5-2005-4cdf-b383-6590b4e4ea1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory 'captions' created or already exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "captions_dir = \"captions\"\n",
        "os.makedirs(captions_dir, exist_ok=True)\n",
        "print(f\"Directory '{captions_dir}' created or already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e44b503",
        "outputId": "8bfd5081-e1cb-4268-b6c1-ee4b3bf03554"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "import os\n",
        "\n",
        "for video_id in video_ids:\n",
        "    if os.path.join(captions_dir, '%(title)s-%(id)s.%(ext)s') not in os.listdir(captions_dir):\n",
        "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "        ydl_opts = {\n",
        "            'writesubtitles': True,\n",
        "            'writeautomaticsub': True,\n",
        "            'subtitleslangs': ['pt'],  \n",
        "            'subtitlesformat': 'srt',\n",
        "            'skip_download': True,\n",
        "            'outtmpl': os.path.join(captions_dir, '%(title)s-%(id)s.%(ext)s'),\n",
        "            'quiet': True,  # Set to True to suppress output\n",
        "            'warnings': True\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(video_url, download=False)\n",
        "                # Now try to download\n",
        "                ydl.download([video_url])\n",
        "                print(f\"‚úì Successfully downloaded captions for: {video_id}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Could not download captions for {video_id}. Error: {e}\")\n",
        "\n",
        "print(f\"\\nCaption download completed for {len(video_ids)} videos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proccess Captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pysrt\n",
        "from typing import Annotated, Literal, TypedDict\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langgraph.prebuilt import ToolNode, tools_condition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### --- PARTE 1: EXTRA√á√ÉO AUTOM√ÅTICA DE IDs DOS ARQUIVOS BAIXADOS ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import pysrt\n",
        "from langchain_core.documents import Document # Importa√ß√£o atualizada\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "def extrair_id_do_nome_arquivo(nome_arquivo):\n",
        "    \"\"\"\n",
        "    Busca o ID de 11 caracteres no final do nome do arquivo gerado pelo yt-dlp.\n",
        "    \"\"\"\n",
        "    # Regex robusto para pegar o ID antes da extens√£o .srt ou .pt.srt\n",
        "    match = re.search(r'-([a-zA-Z0-9_-]{11})\\.(?:[a-z]{2}\\.)?srt$', nome_arquivo)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "def processar_captions_baixadas(captions_dir):\n",
        "    documents = []\n",
        "    print(f\"\\n--- üß† Alimentando C√©rebro: Processando {captions_dir} ---\")\n",
        "    \n",
        "    # Embeddings Multil√≠ngue (Excelente para Portugu√™s)\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "    if not os.path.exists(captions_dir):\n",
        "        print(f\"‚ùå Erro: A pasta {captions_dir} n√£o existe!\")\n",
        "        return None\n",
        "\n",
        "    for filename in os.listdir(captions_dir):\n",
        "        if filename.endswith(\".srt\"):\n",
        "            video_id = extrair_id_do_nome_arquivo(filename)\n",
        "            \n",
        "            if not video_id:\n",
        "                continue\n",
        "                \n",
        "            path_completo = os.path.join(captions_dir, filename)\n",
        "            \n",
        "            # Tenta UTF-8, se falhar vai para ISO-8859-1 (comum em legendas antigas)\n",
        "            try:\n",
        "                subs = pysrt.open(path_completo, encoding='utf-8')\n",
        "            except:\n",
        "                subs = pysrt.open(path_completo, encoding='iso-8859-1')\n",
        "\n",
        "            # Criamos blocos de 10 linhas de legenda para dar contexto ao RAG\n",
        "            step = 10\n",
        "            for i in range(0, len(subs), step):\n",
        "                chunk_subs = subs[i : i + step]\n",
        "                texto = \" \".join([s.text for s in chunk_subs])\n",
        "                texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "                \n",
        "                # Gerar link com timestamp real do v√≠deo\n",
        "                start = chunk_subs[0].start\n",
        "                segundos = (start.hours * 3600) + (start.minutes * 60) + start.seconds\n",
        "                url_com_tempo = f\"https://youtu.be/{video_id}?t={segundos}s\"\n",
        "                \n",
        "                # Criar o objeto Document que o ChromaDB entende\n",
        "                doc = Document(\n",
        "                    page_content=texto,\n",
        "                    metadata={\n",
        "                        \"url\": url_com_tempo, \n",
        "                        \"fonte\": filename,\n",
        "                        \"video_id\": video_id\n",
        "                    }\n",
        "                )\n",
        "                documents.append(doc)\n",
        "                \n",
        "    if not documents:\n",
        "        print(\"‚ö†Ô∏è Nenhuma legenda nova encontrada para processar.\")\n",
        "        return None\n",
        "\n",
        "    # Salva no banco vetorial\n",
        "    vector_db = Chroma.from_documents(\n",
        "        documents=documents,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=\"./db_clone\"\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Sucesso! {len(documents)} novos fragmentos de mem√≥ria integrados.\")\n",
        "    return vector_db\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "# --- CONFIGURA√á√ÉO DO KNOWLEDGE BASE ---\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vector_db = Chroma(persist_directory=\"./db_clone\", embedding_function=embeddings)\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# --- DEFINI√á√ÉO DA FERRAMENTA (TOOL) ---\n",
        "@tool\n",
        "def pesquisar_memoria_renan(query: str) -> str:\n",
        "    \"\"\"Busca trechos de colunas, transcri√ß√µes e pensamentos do Renan Santos sobre um tema.\"\"\"\n",
        "    docs = retriever.invoke(query)\n",
        "    # Formata como o Master Prompt espera (como mem√≥rias)\n",
        "    contexto = \"\\n\\n\".join([f\"[Trecho]: {d.page_content}\" for d in docs])\n",
        "    return contexto\n",
        "\n",
        "# --- CONFIGURA√á√ÉO DO MODELO COM MASTER PROMPT ---\n",
        "with open(\"prompt_clone.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    master_prompt = f.read()\n",
        "\n",
        "# Substitua a cria√ß√£o do llm por:\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.7,\n",
        "    model_kwargs={\"system_instruction\": master_prompt} # Passando via kwargs\n",
        ").bind_tools([pesquisar_memoria_renan])\n",
        "\n",
        "# --- L√ìGICA DO GRAFO (AGENT NODES) ---\n",
        "\n",
        "def chatbot_renan(state: MessagesState):\n",
        "    # O Gemini precisa do hist√≥rico completo para decidir se a ferramenta j√° foi usada\n",
        "    # Injetamos o Master Prompt como SystemMessage aqui para garantir a identidade\n",
        "    messages = [SystemMessage(content=master_prompt)] + state[\"messages\"]\n",
        "    \n",
        "    # Chamada ao modelo\n",
        "    response = llm.invoke(messages)\n",
        "    \n",
        "    # IMPORTANTE: Se o modelo decidir usar uma ferramenta, \n",
        "    # a resposta vir√° com 'tool_calls'. O LangGraph precisa disso.\n",
        "    return {\"messages\": [response]}\n",
        "# --- MONTAGEM DO FLUXO (LANGGRAPH) ---\n",
        "workflow = StateGraph(MessagesState)\n",
        "\n",
        "# 1. Adicionar os N√≥s\n",
        "workflow.add_node(\"chatbot\", chatbot_renan)\n",
        "workflow.add_node(\"tools\", ToolNode([pesquisar_memoria_renan]))\n",
        "\n",
        "# 2. Definir as conex√µes (Arestas)\n",
        "workflow.add_edge(START, \"chatbot\")\n",
        "\n",
        "# O 'tools_condition' decide: se o LLM pediu tool -> vai para 'tools', sen√£o -> termina\n",
        "workflow.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "\n",
        "# Ap√≥s usar a ferramenta, ele volta para o chatbot para processar a informa√ß√£o\n",
        "workflow.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "# Compilar o Agente\n",
        "app = workflow.compile()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CloneRenan",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
